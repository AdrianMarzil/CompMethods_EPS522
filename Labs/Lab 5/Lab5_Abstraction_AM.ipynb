{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-asian",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Lab 5. Abstraction and reusability\n",
    "#### Computational Methods for Geoscience - EPS 400/522\n",
    "#### Instructor: Eric Lindsey\n",
    "\n",
    "Due: Oct. 5, 2023\n",
    "\n",
    "---------\n",
    "\n",
    "Adrian Marziliano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-trail",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some useful imports and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# better looking figures on high-resolution screens\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# reload modules if they have changed - necessary when you are editing your own module\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cc41c-af4c-4539-9352-260e9eb3dee3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 1. Using glob to find files\n",
    "\n",
    "The folder 'timeseries' (you will have to unzip it first) contains a set of GNSS timeseries from the UNR MAGNET site. Let's explore how 'glob' can interact with these files.\n",
    "\n",
    "1. Use glob to get a list of all the files, and print out each filename.\n",
    "\n",
    "2. The sites starting with a letter 'P' were installed under a single project called the 'Plate Boundary Observatory'. Suppose we wanted to list only those files - can you use 'glob' with wildcards to return only the list of names starting with P?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc532dd-0f83-4eb2-876e-25703d4c8447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jovyan/CompMethods_EPS522/Labs/Lab 5\n"
     ]
    }
   ],
   "source": [
    "# Verify that the current working directory has changed\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0974ab-2277-4858-b5b1-3f5c59f9aeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure directory is set to 'timeseries' folder\n",
    "os.chdir('/home/jovyan/CompMethods_EPS522/Labs/Lab 5/timeseries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e030db2e-4898-4a86-a986-1f2ab70f0c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. All files: ['MC10.NA.tenv3', 'SC01.NA.tenv3', 'P034.NA.tenv3', 'P029.NA.tenv3', 'NMLG.NA.tenv3', 'RG01.NA.tenv3', 'P028.NA.tenv3', 'TC01.NA.tenv3', 'AZCN.NA.tenv3', 'CTI4.NA.tenv3']\n",
      "2. Site files with letter P: ['P034.NA.tenv3', 'P029.NA.tenv3', 'P028.NA.tenv3']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of tenv3 files from the \"timeseries\" folder\n",
    "tenv3_files = glob.glob('*.tenv3')\n",
    "#print('All files: ',tenv3_files)\n",
    "\n",
    "# Get a list of the tenv3 files\n",
    "tenv3_Pfiles = glob.glob('P*.tenv3')\n",
    "print(f'1. All files: {tenv3_files}\\n2. Site files with letter P: {tenv3_Pfiles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fefebe-70f9-443d-abc5-7766de048ee0",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 2. Write a module to interact with the GNSS timeseries\n",
    "\n",
    "The module should have (at a minimum) the following four functions with their definitions:\n",
    "\n",
    "fit_timeseries(tlist,ylist) - accepts two lists: t (decimal year) and y (displacement timeseries)  as 1-D numpy arrays, and returns the least-squares velocity and uncertainty for that timeseries. If possible, try to re-use the line-fitting code you wrote for Lab 3 for this purpose.\n",
    "\n",
    "fit_velocities(filename) - accepts a filename, reads in the data, and uses fit_timeseries() to estimate the E, N and U components of velocity for that site.\n",
    "\n",
    "get_coordinates(filename) - accepts a filename and returns the average latitude, longitude, and elevation for that site over the time period.\n",
    "\n",
    "fit_all_velocities(folder,pattern) - accepts a folder name and a 'glob' pattern and returns a pandas data frame with the site name, coordinates, velocities and uncertainties.\n",
    "\n",
    "Finally, import your module and demonstrate each function below to show how it works and what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc28232e-dd66-4f43-9d9e-7c3c319027ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>YYMMMDD</th>\n",
       "      <th>yyyy.yyyy</th>\n",
       "      <th>__MJD</th>\n",
       "      <th>week</th>\n",
       "      <th>d</th>\n",
       "      <th>reflon</th>\n",
       "      <th>_e0(m)</th>\n",
       "      <th>__east(m)</th>\n",
       "      <th>____n0(m)</th>\n",
       "      <th>...</th>\n",
       "      <th>_ant(m)</th>\n",
       "      <th>sig_e(m)</th>\n",
       "      <th>sig_n(m)</th>\n",
       "      <th>sig_u(m)</th>\n",
       "      <th>__corr_en</th>\n",
       "      <th>__corr_eu</th>\n",
       "      <th>__corr_nu</th>\n",
       "      <th>_latitude(deg)</th>\n",
       "      <th>_longitude(deg)</th>\n",
       "      <th>__height(m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY10</td>\n",
       "      <td>1999.3539</td>\n",
       "      <td>51308</td>\n",
       "      <td>1009</td>\n",
       "      <td>1</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.744686</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.067395</td>\n",
       "      <td>-0.150295</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY11</td>\n",
       "      <td>1999.3566</td>\n",
       "      <td>51309</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.741628</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.021724</td>\n",
       "      <td>-0.031813</td>\n",
       "      <td>-0.130306</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY12</td>\n",
       "      <td>1999.3593</td>\n",
       "      <td>51310</td>\n",
       "      <td>1009</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.742445</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>-0.034516</td>\n",
       "      <td>-0.086356</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY13</td>\n",
       "      <td>1999.3621</td>\n",
       "      <td>51311</td>\n",
       "      <td>1009</td>\n",
       "      <td>4</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.744588</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.025548</td>\n",
       "      <td>-0.159457</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY14</td>\n",
       "      <td>1999.3648</td>\n",
       "      <td>51312</td>\n",
       "      <td>1009</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.746577</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>-0.067832</td>\n",
       "      <td>-0.069363</td>\n",
       "      <td>-0.131309</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11JUN15</td>\n",
       "      <td>2011.4524</td>\n",
       "      <td>55727</td>\n",
       "      <td>1640</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.757917</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.024802</td>\n",
       "      <td>-0.068325</td>\n",
       "      <td>-0.079274</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.93348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG10</td>\n",
       "      <td>2011.6057</td>\n",
       "      <td>55783</td>\n",
       "      <td>1648</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.761025</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.178436</td>\n",
       "      <td>-0.087887</td>\n",
       "      <td>-0.207460</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.93815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG11</td>\n",
       "      <td>2011.6085</td>\n",
       "      <td>55784</td>\n",
       "      <td>1648</td>\n",
       "      <td>4</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.757568</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.080286</td>\n",
       "      <td>-0.065957</td>\n",
       "      <td>-0.107477</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.92224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG12</td>\n",
       "      <td>2011.6112</td>\n",
       "      <td>55785</td>\n",
       "      <td>1648</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.761642</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.032072</td>\n",
       "      <td>-0.074917</td>\n",
       "      <td>-0.182729</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.92939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG19</td>\n",
       "      <td>2011.6304</td>\n",
       "      <td>55792</td>\n",
       "      <td>1649</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.757756</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.071012</td>\n",
       "      <td>-0.142379</td>\n",
       "      <td>-0.285496</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.91815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4110 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      site  YYMMMDD  yyyy.yyyy  __MJD  week  d  reflon  _e0(m)  __east(m)  \\\n",
       "0     AZCN  99MAY10  1999.3539  51308  1009  1  -107.9    -977  -0.744686   \n",
       "1     AZCN  99MAY11  1999.3566  51309  1009  2  -107.9    -977  -0.741628   \n",
       "2     AZCN  99MAY12  1999.3593  51310  1009  3  -107.9    -977  -0.742445   \n",
       "3     AZCN  99MAY13  1999.3621  51311  1009  4  -107.9    -977  -0.744588   \n",
       "4     AZCN  99MAY14  1999.3648  51312  1009  5  -107.9    -977  -0.746577   \n",
       "...    ...      ...        ...    ...   ... ..     ...     ...        ...   \n",
       "4105  AZCN  11JUN15  2011.4524  55727  1640  3  -107.9    -977  -0.757917   \n",
       "4106  AZCN  11AUG10  2011.6057  55783  1648  3  -107.9    -977  -0.761025   \n",
       "4107  AZCN  11AUG11  2011.6085  55784  1648  4  -107.9    -977  -0.757568   \n",
       "4108  AZCN  11AUG12  2011.6112  55785  1648  5  -107.9    -977  -0.761642   \n",
       "4109  AZCN  11AUG19  2011.6304  55792  1649  5  -107.9    -977  -0.757756   \n",
       "\n",
       "      ____n0(m)  ...  _ant(m)  sig_e(m)  sig_n(m)  sig_u(m)  __corr_en  \\\n",
       "0       4078731  ...      0.0  0.000894  0.001071  0.003738   0.001207   \n",
       "1       4078731  ...      0.0  0.000838  0.001050  0.003623   0.021724   \n",
       "2       4078731  ...      0.0  0.000868  0.001055  0.003642  -0.001512   \n",
       "3       4078731  ...      0.0  0.001016  0.001200  0.004131   0.036789   \n",
       "4       4078731  ...      0.0  0.001342  0.001580  0.005565  -0.067832   \n",
       "...         ...  ...      ...       ...       ...       ...        ...   \n",
       "4105    4078731  ...      0.0  0.000828  0.001068  0.003440   0.024802   \n",
       "4106    4078731  ...      0.0  0.001333  0.001489  0.005270   0.178436   \n",
       "4107    4078731  ...      0.0  0.002455  0.002242  0.006725   0.080286   \n",
       "4108    4078731  ...      0.0  0.008280  0.003808  0.008938   0.032072   \n",
       "4109    4078731  ...      0.0  0.006698  0.003288  0.007855   0.071012   \n",
       "\n",
       "      __corr_eu  __corr_nu  _latitude(deg)  _longitude(deg)  __height(m)  \n",
       "0      0.067395  -0.150295       36.839793      -107.910961   1862.93747  \n",
       "1     -0.031813  -0.130306       36.839793      -107.910961   1862.93534  \n",
       "2     -0.034516  -0.086356       36.839793      -107.910961   1862.93970  \n",
       "3      0.025548  -0.159457       36.839793      -107.910961   1862.93930  \n",
       "4     -0.069363  -0.131309       36.839793      -107.910961   1862.93748  \n",
       "...         ...        ...             ...              ...          ...  \n",
       "4105  -0.068325  -0.079274       36.839793      -107.910963   1862.93348  \n",
       "4106  -0.087887  -0.207460       36.839793      -107.910963   1862.93815  \n",
       "4107  -0.065957  -0.107477       36.839793      -107.910963   1862.92224  \n",
       "4108  -0.074917  -0.182729       36.839793      -107.910963   1862.92939  \n",
       "4109  -0.142379  -0.285496       36.839793      -107.910963   1862.91815  \n",
       "\n",
       "[4110 rows x 23 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path ='../timeseries/AZCN.NA.tenv3'\n",
    "tenv3_sample = pd.read_csv(file_path, delim_whitespace=True )\n",
    "tenv3_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d33092bf-c445-4262-820e-f65cdd8dec0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity: -0.000861 velocity uncertainty: 0.000098\n"
     ]
    }
   ],
   "source": [
    "def fit_timeseries(tlist, ylist):\n",
    "    \"\"\"\n",
    "    Fit a linear model to a displacement timeseries.\n",
    "    \n",
    "    Args:\n",
    "    tlist (numpy.ndarray): 1-D numpy array of decimal years.\n",
    "    ylist (numpy.ndarray): 1-D numpy array of displacement timeseries.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the least-squares velocity and its uncertainty.\n",
    "    \"\"\"\n",
    "    A = np.vstack([tlist, np.ones(len(tlist))]).T\n",
    "    m, c = np.linalg.lstsq(A, ylist, rcond=None)[0]\n",
    "    \n",
    "    # Calculate the uncertainty of the velocity\n",
    "    residuals = ylist - (m * tlist + c)\n",
    "    sigma = np.std(residuals)\n",
    "    velocity_uncertainty = sigma / np.sqrt(len(tlist))\n",
    "    \n",
    "    return m, velocity_uncertainty\n",
    "\n",
    "\n",
    "# Sample function usage with sample data:\n",
    "tlist = tenv3_sample['yyyy.yyyy']\n",
    "ylist = tenv3_sample['____up(m)']\n",
    "\n",
    "m, velocity_uncertainty = fit_timeseries(tlist, ylist)\n",
    "\n",
    "print(f'velocity: {m:0.6f} velocity uncertainty: {velocity_uncertainty:0.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dae0125-202d-4531-97ca-0bcf3f577aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.845796\n",
      "1       0.843869\n",
      "2       0.845974\n",
      "3       0.846115\n",
      "4       0.845767\n",
      "          ...   \n",
      "4105    0.876575\n",
      "4106    0.883958\n",
      "4107    0.878386\n",
      "4108    0.881139\n",
      "4109    0.877338\n",
      "Name: _north(m), Length: 4110, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def fit_velocities(filename):\n",
    "    \"\"\"\n",
    "    Estimate the E, N, and U components of velocity for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing timeseries data.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing site name, E, N, and U velocities with uncertainties.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    tlist = data[:, 0]\n",
    "    east_displacement = data[:, 1]\n",
    "    north_displacement = data[:, 2]\n",
    "    vertical_displacement = data[:, 3]\n",
    "    \n",
    "    east_velocity, east_uncertainty = fit_timeseries(tlist, east_displacement)\n",
    "    north_velocity, north_uncertainty = fit_timeseries(tlist, north_displacement)\n",
    "    vertical_velocity, vertical_uncertainty = fit_timeseries(tlist, vertical_displacement)\n",
    "    \n",
    "    return {\n",
    "        'Site Name': filename,\n",
    "        'E Velocity': east_velocity,\n",
    "        'N Velocity': north_velocity,\n",
    "        'U Velocity': vertical_velocity,\n",
    "        'E Velocity Uncertainty': east_uncertainty,\n",
    "        'N Velocity Uncertainty': north_uncertainty,\n",
    "        'U Velocity Uncertainty': vertical_uncertainty\n",
    "    }\n",
    "\n",
    "# Sample function usage with sample data:\n",
    "filename = tenv3_sample\n",
    "east_velocity = tenv3_sample['__east(m)']\n",
    "north_velocity = tenv3_sample['_north(m)']\n",
    "vertical_velocity = tenv3_sample['____up(m)']\n",
    "\n",
    "print(north_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "702747e7-45aa-4000-aa75-e0bd26074e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_coordinates(filename):\n",
    "    \"\"\"\n",
    "    Get the average latitude, longitude, and elevation for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing site information.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing latitude, longitude, and elevation.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    latitudes = data[:, 0]\n",
    "    longitudes = data[:, 1]\n",
    "    elevations = data[:, 2]\n",
    "    \n",
    "    avg_latitude = np.mean(latitudes)\n",
    "    avg_longitude = np.mean(longitudes)\n",
    "    avg_elevation = np.mean(elevations)\n",
    "    \n",
    "    return avg_latitude, avg_longitude, avg_elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a3b6aad-275d-44fc-8063-45fc501585a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_latitude' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mavg_latitude\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_latitude' is not defined"
     ]
    }
   ],
   "source": [
    "print(avg_latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cba95-9568-4e92-a14f-44163332110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def fit_timeseries(tlist, ylist):\n",
    "    \"\"\"\n",
    "    Fit a linear model to a displacement timeseries.\n",
    "    \n",
    "    Args:\n",
    "    tlist (numpy.ndarray): 1-D numpy array of decimal years.\n",
    "    ylist (numpy.ndarray): 1-D numpy array of displacement timeseries.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the least-squares velocity and its uncertainty.\n",
    "    \"\"\"\n",
    "    A = np.vstack([tlist, np.ones(len(tlist))]).T\n",
    "    m, c = np.linalg.lstsq(A, ylist, rcond=None)[0]\n",
    "    \n",
    "    # Calculate the uncertainty of the velocity\n",
    "    residuals = ylist - (m * tlist + c)\n",
    "    sigma = np.std(residuals)\n",
    "    velocity_uncertainty = sigma / np.sqrt(len(tlist))\n",
    "    \n",
    "    return m, velocity_uncertainty\n",
    "\n",
    "def fit_velocities(filename):\n",
    "    \"\"\"\n",
    "    Estimate the E, N, and U components of velocity for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing timeseries data.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing site name, E, N, and U velocities with uncertainties.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    tlist = data[:, 0]\n",
    "    east_displacement = data[:, 1]\n",
    "    north_displacement = data[:, 2]\n",
    "    vertical_displacement = data[:, 3]\n",
    "    \n",
    "    east_velocity, east_uncertainty = fit_timeseries(tlist, east_displacement)\n",
    "    north_velocity, north_uncertainty = fit_timeseries(tlist, north_displacement)\n",
    "    vertical_velocity, vertical_uncertainty = fit_timeseries(tlist, vertical_displacement)\n",
    "    \n",
    "    return {\n",
    "        'Site Name': filename,\n",
    "        'E Velocity': east_velocity,\n",
    "        'N Velocity': north_velocity,\n",
    "        'U Velocity': vertical_velocity,\n",
    "        'E Velocity Uncertainty': east_uncertainty,\n",
    "        'N Velocity Uncertainty': north_uncertainty,\n",
    "        'U Velocity Uncertainty': vertical_uncertainty\n",
    "    }\n",
    "\n",
    "def get_coordinates(filename):\n",
    "    \"\"\"\n",
    "    Get the average latitude, longitude, and elevation for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing site information.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing latitude, longitude, and elevation.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    latitudes = data[:, 0]\n",
    "    longitudes = data[:, 1]\n",
    "    elevations = data[:, 2]\n",
    "    \n",
    "    avg_latitude = np.mean(latitudes)\n",
    "    avg_longitude = np.mean(longitudes)\n",
    "    avg_elevation = np.mean(elevations)\n",
    "    \n",
    "    return avg_latitude, avg_longitude, avg_elevation\n",
    "\n",
    "def fit_all_velocities(folder, pattern):\n",
    "    \"\"\"\n",
    "    Fit velocities and collect site information for all files matching the pattern in a folder.\n",
    "    \n",
    "    Args:\n",
    "    folder (str): Name of the folder containing the data files.\n",
    "    pattern (str): Glob pattern to filter files.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing site name, coordinates, velocities, and uncertainties.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob(f\"{folder}/{pattern}\")\n",
    "    \n",
    "    data_list = []\n",
    "    for filename in file_list:\n",
    "        site_info = get_coordinates(filename)\n",
    "        velocities = fit_velocities(filename)\n",
    "        site_info.update(velocities)\n",
    "        data_list.append(site_info)\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = 'data_folder'\n",
    "    file_pattern = '*.csv'\n",
    "    result_df = fit_all_velocities(folder_path, file_pattern)\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff7646-860f-4a87-accd-a77e1c41d0a4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 3. Upload the module to GitHub, along with a README.md file explaining briefly how to use it.\n",
    "\n",
    "Enter a link to your GitHub repository here for me to check out: \n",
    "\n",
    "GitHub: [AdrianMarzil](https://github.com/AdrianMarzil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c8fb3-05cd-486f-8cac-32ff52075e84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8beca1f-c264-4bb0-8bdb-393a3f1194b3",
   "metadata": {},
   "source": [
    "### 4. Use the timeseries calculation module you created\n",
    "\n",
    "Using at most 5 lines of code, import the module you created above and use it to estimate the timeseries for all 10 of the sites, print them out, and save the results to a new file 'site_velocities.csv'. Feel free to download more sites as well and put them in the folder too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394f71a-8eba-42d7-81a9-23c5b108a9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coupled-terminology",
   "metadata": {},
   "source": [
    "### 5. Re-use your module to estimate sea level rise rates\n",
    "\n",
    "Go to the following page and download at least 5 monthly sea level timeseries spanning at least 100 years: https://psmsl.org/products/gloss/glossmap.html. Place them in a new folder.\n",
    "\n",
    "(To download the data: click a station icon on the map, then click the station number/name (first link in the pop-up, e.g. \"155: Honolulu\". Then right-click the link next to the plot of monthly data (\"Download monthly mean sea level data.\") and save it as a file.)\n",
    "\n",
    "Now, create a new function \"fit_tide_gauge\" in your module that re-uses your function \"fit_timeseries\" to return the relative sea level rate of change for a given station. \n",
    "\n",
    "Next, modify your function \"fit_all_velocities\" to accept a \"type\" parameter (GNSS or tide), and re-use it to estimate the rates for all the tide gauges you downloaded. Print out the results below.\n",
    "\n",
    "Finally, update your github repository with this new version of the module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dee49e-817a-47b2-af0d-fb6e811650f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
