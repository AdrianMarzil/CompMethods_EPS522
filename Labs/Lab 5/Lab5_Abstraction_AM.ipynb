{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-asian",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Lab 5. Abstraction and reusability\n",
    "#### Computational Methods for Geoscience - EPS 400/522\n",
    "#### Instructor: Eric Lindsey\n",
    "\n",
    "Due: Oct. 5, 2023\n",
    "\n",
    "---------\n",
    "\n",
    "Adrian Marziliano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "center-trail",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# some useful imports and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# better looking figures on high-resolution screens\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# reload modules if they have changed - necessary when you are editing your own module\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cc41c-af4c-4539-9352-260e9eb3dee3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 1. Using glob to find files\n",
    "\n",
    "The folder 'timeseries' (you will have to unzip it first) contains a set of GNSS timeseries from the UNR MAGNET site. Let's explore how 'glob' can interact with these files.\n",
    "\n",
    "1. Use glob to get a list of all the files, and print out each filename.\n",
    "\n",
    "2. The sites starting with a letter 'P' were installed under a single project called the 'Plate Boundary Observatory'. Suppose we wanted to list only those files - can you use 'glob' with wildcards to return only the list of names starting with P?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dc532dd-0f83-4eb2-876e-25703d4c8447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jovyan/CompMethods_EPS522/Labs/Lab 5/timeseries\n"
     ]
    }
   ],
   "source": [
    "# Verify that the current working directory has changed\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f0974ab-2277-4858-b5b1-3f5c59f9aeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure directory is set to 'timeseries' folder\n",
    "os.chdir('/home/jovyan/CompMethods_EPS522/Labs/Lab 5/timeseries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e030db2e-4898-4a86-a986-1f2ab70f0c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. All files: ['MC10.NA.tenv3', 'SC01.NA.tenv3', 'P034.NA.tenv3', 'P029.NA.tenv3', 'NMLG.NA.tenv3', 'RG01.NA.tenv3', 'P028.NA.tenv3', 'TC01.NA.tenv3', 'AZCN.NA.tenv3', 'CTI4.NA.tenv3']\n",
      "2. Site files with letter P: ['P034.NA.tenv3', 'P029.NA.tenv3', 'P028.NA.tenv3']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of tenv3 files from the \"timeseries\" folder\n",
    "tenv3_files = glob.glob('*.tenv3')\n",
    "#print('All files: ',tenv3_files)\n",
    "\n",
    "# Get a list of the tenv3 files\n",
    "tenv3_Pfiles = glob.glob('P*.tenv3')\n",
    "print(f'1. All files: {tenv3_files}\\n2. Site files with letter P: {tenv3_Pfiles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fefebe-70f9-443d-abc5-7766de048ee0",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 2. Write a module to interact with the GNSS timeseries\n",
    "\n",
    "The module should have (at a minimum) the following four functions with their definitions:\n",
    "\n",
    "fit_timeseries(tlist,ylist) - accepts two lists: t (decimal year) and y (displacement timeseries)  as 1-D numpy arrays, and returns the least-squares velocity and uncertainty for that timeseries. If possible, try to re-use the line-fitting code you wrote for Lab 3 for this purpose.\n",
    "\n",
    "fit_velocities(filename) - accepts a filename, reads in the data, and uses fit_timeseries() to estimate the E, N and U components of velocity for that site.\n",
    "\n",
    "get_coordinates(filename) - accepts a filename and returns the average latitude, longitude, and elevation for that site over the time period.\n",
    "\n",
    "fit_all_velocities(folder,pattern) - accepts a folder name and a 'glob' pattern and returns a pandas data frame with the site name, coordinates, velocities and uncertainties.\n",
    "\n",
    "Finally, import your module and demonstrate each function below to show how it works and what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc28232e-dd66-4f43-9d9e-7c3c319027ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>YYMMMDD</th>\n",
       "      <th>yyyy.yyyy</th>\n",
       "      <th>__MJD</th>\n",
       "      <th>week</th>\n",
       "      <th>d</th>\n",
       "      <th>reflon</th>\n",
       "      <th>_e0(m)</th>\n",
       "      <th>__east(m)</th>\n",
       "      <th>____n0(m)</th>\n",
       "      <th>...</th>\n",
       "      <th>_ant(m)</th>\n",
       "      <th>sig_e(m)</th>\n",
       "      <th>sig_n(m)</th>\n",
       "      <th>sig_u(m)</th>\n",
       "      <th>__corr_en</th>\n",
       "      <th>__corr_eu</th>\n",
       "      <th>__corr_nu</th>\n",
       "      <th>_latitude(deg)</th>\n",
       "      <th>_longitude(deg)</th>\n",
       "      <th>__height(m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MC10</td>\n",
       "      <td>09JUL23</td>\n",
       "      <td>2009.5578</td>\n",
       "      <td>55035</td>\n",
       "      <td>1541</td>\n",
       "      <td>4</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.665013</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.219095</td>\n",
       "      <td>0.117957</td>\n",
       "      <td>-0.134141</td>\n",
       "      <td>38.455599</td>\n",
       "      <td>-107.878456</td>\n",
       "      <td>1808.59306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MC10</td>\n",
       "      <td>09AUG02</td>\n",
       "      <td>2009.5852</td>\n",
       "      <td>55045</td>\n",
       "      <td>1543</td>\n",
       "      <td>0</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.663334</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.055874</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>-0.111692</td>\n",
       "      <td>38.455599</td>\n",
       "      <td>-107.878456</td>\n",
       "      <td>1808.59275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MC10</td>\n",
       "      <td>09AUG03</td>\n",
       "      <td>2009.5880</td>\n",
       "      <td>55046</td>\n",
       "      <td>1543</td>\n",
       "      <td>1</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.662829</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.048827</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>-0.132294</td>\n",
       "      <td>38.455599</td>\n",
       "      <td>-107.878456</td>\n",
       "      <td>1808.59670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MC10</td>\n",
       "      <td>09AUG04</td>\n",
       "      <td>2009.5907</td>\n",
       "      <td>55047</td>\n",
       "      <td>1543</td>\n",
       "      <td>2</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.662793</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.021409</td>\n",
       "      <td>-0.123357</td>\n",
       "      <td>38.455599</td>\n",
       "      <td>-107.878456</td>\n",
       "      <td>1808.59229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MC10</td>\n",
       "      <td>09AUG05</td>\n",
       "      <td>2009.5934</td>\n",
       "      <td>55048</td>\n",
       "      <td>1543</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.661817</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.044206</td>\n",
       "      <td>-0.008356</td>\n",
       "      <td>-0.102855</td>\n",
       "      <td>38.455599</td>\n",
       "      <td>-107.878456</td>\n",
       "      <td>1808.58889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>MC10</td>\n",
       "      <td>23SEP05</td>\n",
       "      <td>2023.6769</td>\n",
       "      <td>60192</td>\n",
       "      <td>2278</td>\n",
       "      <td>2</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.660490</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.020828</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>38.455598</td>\n",
       "      <td>-107.878458</td>\n",
       "      <td>1808.57982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>MC10</td>\n",
       "      <td>23SEP06</td>\n",
       "      <td>2023.6797</td>\n",
       "      <td>60193</td>\n",
       "      <td>2278</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.661740</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.028177</td>\n",
       "      <td>0.026276</td>\n",
       "      <td>-0.080705</td>\n",
       "      <td>38.455598</td>\n",
       "      <td>-107.878458</td>\n",
       "      <td>1808.58355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>MC10</td>\n",
       "      <td>23SEP07</td>\n",
       "      <td>2023.6824</td>\n",
       "      <td>60194</td>\n",
       "      <td>2278</td>\n",
       "      <td>4</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.661126</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>-0.090697</td>\n",
       "      <td>38.455598</td>\n",
       "      <td>-107.878458</td>\n",
       "      <td>1808.58111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>MC10</td>\n",
       "      <td>23SEP08</td>\n",
       "      <td>2023.6851</td>\n",
       "      <td>60195</td>\n",
       "      <td>2278</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.661531</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.054616</td>\n",
       "      <td>-0.105154</td>\n",
       "      <td>38.455598</td>\n",
       "      <td>-107.878458</td>\n",
       "      <td>1808.57926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>MC10</td>\n",
       "      <td>23SEP09</td>\n",
       "      <td>2023.6879</td>\n",
       "      <td>60196</td>\n",
       "      <td>2278</td>\n",
       "      <td>6</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.662829</td>\n",
       "      <td>4258069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>-0.100789</td>\n",
       "      <td>38.455598</td>\n",
       "      <td>-107.878458</td>\n",
       "      <td>1808.57708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5081 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      site  YYMMMDD  yyyy.yyyy  __MJD  week  d  reflon  _e0(m)  __east(m)  \\\n",
       "0     MC10  09JUL23  2009.5578  55035  1541  4  -107.9    1880   0.665013   \n",
       "1     MC10  09AUG02  2009.5852  55045  1543  0  -107.9    1880   0.663334   \n",
       "2     MC10  09AUG03  2009.5880  55046  1543  1  -107.9    1880   0.662829   \n",
       "3     MC10  09AUG04  2009.5907  55047  1543  2  -107.9    1880   0.662793   \n",
       "4     MC10  09AUG05  2009.5934  55048  1543  3  -107.9    1880   0.661817   \n",
       "...    ...      ...        ...    ...   ... ..     ...     ...        ...   \n",
       "5076  MC10  23SEP05  2023.6769  60192  2278  2  -107.9    1880   0.660490   \n",
       "5077  MC10  23SEP06  2023.6797  60193  2278  3  -107.9    1880   0.661740   \n",
       "5078  MC10  23SEP07  2023.6824  60194  2278  4  -107.9    1880   0.661126   \n",
       "5079  MC10  23SEP08  2023.6851  60195  2278  5  -107.9    1880   0.661531   \n",
       "5080  MC10  23SEP09  2023.6879  60196  2278  6  -107.9    1880   0.662829   \n",
       "\n",
       "      ____n0(m)  ...  _ant(m)  sig_e(m)  sig_n(m)  sig_u(m)  __corr_en  \\\n",
       "0       4258069  ...      0.0  0.001183  0.001354  0.004575   0.219095   \n",
       "1       4258069  ...      0.0  0.000707  0.000866  0.002770   0.055874   \n",
       "2       4258069  ...      0.0  0.000706  0.000860  0.002820   0.048827   \n",
       "3       4258069  ...      0.0  0.000706  0.000845  0.002786   0.030142   \n",
       "4       4258069  ...      0.0  0.000721  0.000874  0.002878   0.044206   \n",
       "...         ...  ...      ...       ...       ...       ...        ...   \n",
       "5076    4258069  ...      0.0  0.000678  0.000806  0.002669   0.020828   \n",
       "5077    4258069  ...      0.0  0.000676  0.000809  0.002674   0.028177   \n",
       "5078    4258069  ...      0.0  0.000696  0.000831  0.002773   0.016043   \n",
       "5079    4258069  ...      0.0  0.000689  0.000813  0.002698   0.012066   \n",
       "5080    4258069  ...      0.0  0.000668  0.000798  0.002623   0.007563   \n",
       "\n",
       "      __corr_eu  __corr_nu  _latitude(deg)  _longitude(deg)  __height(m)  \n",
       "0      0.117957  -0.134141       38.455599      -107.878456   1808.59306  \n",
       "1      0.005951  -0.111692       38.455599      -107.878456   1808.59275  \n",
       "2      0.006108  -0.132294       38.455599      -107.878456   1808.59670  \n",
       "3      0.021409  -0.123357       38.455599      -107.878456   1808.59229  \n",
       "4     -0.008356  -0.102855       38.455599      -107.878456   1808.58889  \n",
       "...         ...        ...             ...              ...          ...  \n",
       "5076   0.007795  -0.099866       38.455598      -107.878458   1808.57982  \n",
       "5077   0.026276  -0.080705       38.455598      -107.878458   1808.58355  \n",
       "5078   0.033969  -0.090697       38.455598      -107.878458   1808.58111  \n",
       "5079   0.054616  -0.105154       38.455598      -107.878458   1808.57926  \n",
       "5080   0.008713  -0.100789       38.455598      -107.878458   1808.57708  \n",
       "\n",
       "[5081 rows x 23 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path ='../timeseries/MC10.NA.tenv3'\n",
    "tenv3_sample = pd.read_csv(file_path, delim_whitespace=True )\n",
    "tenv3_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d33092bf-c445-4262-820e-f65cdd8dec0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: -0.000861 velocity uncertainty: 0.000098\n"
     ]
    }
   ],
   "source": [
    "file_path ='../timeseries/AZCN.NA.tenv3'\n",
    "tenv3_sample = pd.read_csv(file_path, delim_whitespace=True )\n",
    "\n",
    "def fit_timeseries(tlist, ylist):\n",
    "    \"\"\"\n",
    "    Fit a linear model to a displacement timeseries.\n",
    "    \n",
    "    Args:\n",
    "    tlist (numpy.ndarray): 1-D numpy array of decimal years.\n",
    "    ylist (numpy.ndarray): 1-D numpy array of displacement timeseries.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the least-squares velocity and its uncertainty.\n",
    "    \"\"\"\n",
    "    A = np.vstack([tlist, np.ones(len(tlist))]).T\n",
    "    m, c = np.linalg.lstsq(A, ylist, rcond=None)[0]\n",
    "    \n",
    "    # Calculate the uncertainty of the velocity\n",
    "    residuals = ylist - (m * tlist + c)\n",
    "    sigma = np.std(residuals)\n",
    "    velocity_uncertainty = sigma / np.sqrt(len(tlist))\n",
    "    \n",
    "    return m, velocity_uncertainty\n",
    "\n",
    "\n",
    "# Sample function usage with sample data:\n",
    "tlist = tenv3_sample['yyyy.yyyy']\n",
    "ylist = tenv3_sample['____up(m)']\n",
    "\n",
    "m, velocity_uncertainty = fit_timeseries(tlist, ylist)\n",
    "\n",
    "print(f'm: {m:0.6f} velocity uncertainty: {velocity_uncertainty:0.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae0125-202d-4531-97ca-0bcf3f577aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_velocities(filename):\n",
    "    \"\"\"\n",
    "    Estimate the E, N, and U components of velocity for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing timeseries data.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing site name, E, N, and U velocities with uncertainties.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    tlist = data[:, 0]\n",
    "    east_displacement = data[:, 1]\n",
    "    north_displacement = data[:, 2]\n",
    "    vertical_displacement = data[:, 3]\n",
    "    \n",
    "    east_velocity, east_uncertainty = fit_timeseries(tlist, east_displacement)\n",
    "    north_velocity, north_uncertainty = fit_timeseries(tlist, north_displacement)\n",
    "    vertical_velocity, vertical_uncertainty = fit_timeseries(tlist, vertical_displacement)\n",
    "    \n",
    "    return {\n",
    "        'Site Name': filename,\n",
    "        'E Velocity': east_velocity,\n",
    "        'N Velocity': north_velocity,\n",
    "        'U Velocity': vertical_velocity,\n",
    "        'E Velocity Uncertainty': east_uncertainty,\n",
    "        'N Velocity Uncertainty': north_uncertainty,\n",
    "        'U Velocity Uncertainty': vertical_uncertainty\n",
    "    }\n",
    "\n",
    "# Sample function usage with sample data:\n",
    "filename = tenv3_sample\n",
    "east_velocity = tenv3_sample['__east(m)']\n",
    "north_velocity = tenv3_sample['__north(m)']\n",
    "vertical_velocity = tenv3_sample['___up(m)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cba95-9568-4e92-a14f-44163332110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def fit_timeseries(tlist, ylist):\n",
    "    \"\"\"\n",
    "    Fit a linear model to a displacement timeseries.\n",
    "    \n",
    "    Args:\n",
    "    tlist (numpy.ndarray): 1-D numpy array of decimal years.\n",
    "    ylist (numpy.ndarray): 1-D numpy array of displacement timeseries.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the least-squares velocity and its uncertainty.\n",
    "    \"\"\"\n",
    "    A = np.vstack([tlist, np.ones(len(tlist))]).T\n",
    "    m, c = np.linalg.lstsq(A, ylist, rcond=None)[0]\n",
    "    \n",
    "    # Calculate the uncertainty of the velocity\n",
    "    residuals = ylist - (m * tlist + c)\n",
    "    sigma = np.std(residuals)\n",
    "    velocity_uncertainty = sigma / np.sqrt(len(tlist))\n",
    "    \n",
    "    return m, velocity_uncertainty\n",
    "\n",
    "def fit_velocities(filename):\n",
    "    \"\"\"\n",
    "    Estimate the E, N, and U components of velocity for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing timeseries data.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing site name, E, N, and U velocities with uncertainties.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    tlist = data[:, 0]\n",
    "    east_displacement = data[:, 1]\n",
    "    north_displacement = data[:, 2]\n",
    "    vertical_displacement = data[:, 3]\n",
    "    \n",
    "    east_velocity, east_uncertainty = fit_timeseries(tlist, east_displacement)\n",
    "    north_velocity, north_uncertainty = fit_timeseries(tlist, north_displacement)\n",
    "    vertical_velocity, vertical_uncertainty = fit_timeseries(tlist, vertical_displacement)\n",
    "    \n",
    "    return {\n",
    "        'Site Name': filename,\n",
    "        'E Velocity': east_velocity,\n",
    "        'N Velocity': north_velocity,\n",
    "        'U Velocity': vertical_velocity,\n",
    "        'E Velocity Uncertainty': east_uncertainty,\n",
    "        'N Velocity Uncertainty': north_uncertainty,\n",
    "        'U Velocity Uncertainty': vertical_uncertainty\n",
    "    }\n",
    "\n",
    "def get_coordinates(filename):\n",
    "    \"\"\"\n",
    "    Get the average latitude, longitude, and elevation for a site.\n",
    "    \n",
    "    Args:\n",
    "    filename (str): Name of the file containing site information.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing latitude, longitude, and elevation.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    latitudes = data[:, 0]\n",
    "    longitudes = data[:, 1]\n",
    "    elevations = data[:, 2]\n",
    "    \n",
    "    avg_latitude = np.mean(latitudes)\n",
    "    avg_longitude = np.mean(longitudes)\n",
    "    avg_elevation = np.mean(elevations)\n",
    "    \n",
    "    return avg_latitude, avg_longitude, avg_elevation\n",
    "\n",
    "def fit_all_velocities(folder, pattern):\n",
    "    \"\"\"\n",
    "    Fit velocities and collect site information for all files matching the pattern in a folder.\n",
    "    \n",
    "    Args:\n",
    "    folder (str): Name of the folder containing the data files.\n",
    "    pattern (str): Glob pattern to filter files.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing site name, coordinates, velocities, and uncertainties.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob(f\"{folder}/{pattern}\")\n",
    "    \n",
    "    data_list = []\n",
    "    for filename in file_list:\n",
    "        site_info = get_coordinates(filename)\n",
    "        velocities = fit_velocities(filename)\n",
    "        site_info.update(velocities)\n",
    "        data_list.append(site_info)\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = 'data_folder'\n",
    "    file_pattern = '*.csv'\n",
    "    result_df = fit_all_velocities(folder_path, file_pattern)\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff7646-860f-4a87-accd-a77e1c41d0a4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 3. Upload the module to GitHub, along with a README.md file explaining briefly how to use it.\n",
    "\n",
    "Enter a link to your GitHub repository here for me to check out: \n",
    "\n",
    "GitHub: [AdrianMarzil](https://github.com/AdrianMarzil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c8fb3-05cd-486f-8cac-32ff52075e84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8beca1f-c264-4bb0-8bdb-393a3f1194b3",
   "metadata": {},
   "source": [
    "### 4. Use the timeseries calculation module you created\n",
    "\n",
    "Using at most 5 lines of code, import the module you created above and use it to estimate the timeseries for all 10 of the sites, print them out, and save the results to a new file 'site_velocities.csv'. Feel free to download more sites as well and put them in the folder too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394f71a-8eba-42d7-81a9-23c5b108a9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coupled-terminology",
   "metadata": {},
   "source": [
    "### 5. Re-use your module to estimate sea level rise rates\n",
    "\n",
    "Go to the following page and download at least 5 monthly sea level timeseries spanning at least 100 years: https://psmsl.org/products/gloss/glossmap.html. Place them in a new folder.\n",
    "\n",
    "(To download the data: click a station icon on the map, then click the station number/name (first link in the pop-up, e.g. \"155: Honolulu\". Then right-click the link next to the plot of monthly data (\"Download monthly mean sea level data.\") and save it as a file.)\n",
    "\n",
    "Now, create a new function \"fit_tide_gauge\" in your module that re-uses your function \"fit_timeseries\" to return the relative sea level rate of change for a given station. \n",
    "\n",
    "Next, modify your function \"fit_all_velocities\" to accept a \"type\" parameter (GNSS or tide), and re-use it to estimate the rates for all the tide gauges you downloaded. Print out the results below.\n",
    "\n",
    "Finally, update your github repository with this new version of the module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dee49e-817a-47b2-af0d-fb6e811650f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
