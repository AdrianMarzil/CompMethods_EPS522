{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "direct-asian",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Lab 5. Abstraction and reusability\n",
    "#### Computational Methods for Geoscience - EPS 400/522\n",
    "#### Instructor: Eric Lindsey\n",
    "\n",
    "Due: Oct. 5, 2023\n",
    "\n",
    "---------\n",
    "\n",
    "Adrian Marziliano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "center-trail",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# some useful imports and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# better looking figures on high-resolution screens\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# reload modules if they have changed - necessary when you are editing your own module\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cc41c-af4c-4539-9352-260e9eb3dee3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 1. Using glob to find files\n",
    "\n",
    "The folder 'timeseries' (you will have to unzip it first) contains a set of GNSS timeseries from the UNR MAGNET site. Let's explore how 'glob' can interact with these files.\n",
    "\n",
    "1. Use glob to get a list of all the files, and print out each filename.\n",
    "\n",
    "2. The sites starting with a letter 'P' were installed under a single project called the 'Plate Boundary Observatory'. Suppose we wanted to list only those files - can you use 'glob' with wildcards to return only the list of names starting with P?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dc532dd-0f83-4eb2-876e-25703d4c8447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5\n"
     ]
    }
   ],
   "source": [
    "# Verify that the current working directory has changed\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f0974ab-2277-4858-b5b1-3f5c59f9aeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure directory is set to 'timeseries' folder\n",
    "#os.chdir('/home/jovyan/CompMethods_EPS522/Labs/Lab 5/timeseries/')\n",
    "os.chdir('../Lab 5/timeseries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e030db2e-4898-4a86-a986-1f2ab70f0c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. All files: ['RG01.NA.tenv3', 'SC01.NA.tenv3', 'AZCN.NA.tenv3', 'P034.NA.tenv3', 'P028.NA.tenv3', 'P029.NA.tenv3', 'NMLG.NA.tenv3', 'CTI4.NA.tenv3', 'MC10.NA.tenv3', 'TC01.NA.tenv3']\n",
      "2. Site files with letter P: ['P034.NA.tenv3', 'P028.NA.tenv3', 'P029.NA.tenv3']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of tenv3 files from the \"timeseries\" folder\n",
    "tenv3_files = glob.glob('*.tenv3')\n",
    "#print('All files: ',tenv3_files)\n",
    "\n",
    "# Get a list of the tenv3 files\n",
    "tenv3_Pfiles = glob.glob('P*.tenv3')\n",
    "print(f'1. All files: {tenv3_files}\\n2. Site files with letter P: {tenv3_Pfiles}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>YYMMMDD</th>\n",
       "      <th>yyyy.yyyy</th>\n",
       "      <th>__MJD</th>\n",
       "      <th>week</th>\n",
       "      <th>d</th>\n",
       "      <th>reflon</th>\n",
       "      <th>_e0(m)</th>\n",
       "      <th>__east(m)</th>\n",
       "      <th>____n0(m)</th>\n",
       "      <th>...</th>\n",
       "      <th>_ant(m)</th>\n",
       "      <th>sig_e(m)</th>\n",
       "      <th>sig_n(m)</th>\n",
       "      <th>sig_u(m)</th>\n",
       "      <th>__corr_en</th>\n",
       "      <th>__corr_eu</th>\n",
       "      <th>__corr_nu</th>\n",
       "      <th>_latitude(deg)</th>\n",
       "      <th>_longitude(deg)</th>\n",
       "      <th>__height(m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY10</td>\n",
       "      <td>1999.3539</td>\n",
       "      <td>51308</td>\n",
       "      <td>1009</td>\n",
       "      <td>1</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.744686</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.067395</td>\n",
       "      <td>-0.150295</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY11</td>\n",
       "      <td>1999.3566</td>\n",
       "      <td>51309</td>\n",
       "      <td>1009</td>\n",
       "      <td>2</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.741628</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.021724</td>\n",
       "      <td>-0.031813</td>\n",
       "      <td>-0.130306</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY12</td>\n",
       "      <td>1999.3593</td>\n",
       "      <td>51310</td>\n",
       "      <td>1009</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.742445</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>-0.034516</td>\n",
       "      <td>-0.086356</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY13</td>\n",
       "      <td>1999.3621</td>\n",
       "      <td>51311</td>\n",
       "      <td>1009</td>\n",
       "      <td>4</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.744588</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.025548</td>\n",
       "      <td>-0.159457</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>99MAY14</td>\n",
       "      <td>1999.3648</td>\n",
       "      <td>51312</td>\n",
       "      <td>1009</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.746577</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>-0.067832</td>\n",
       "      <td>-0.069363</td>\n",
       "      <td>-0.131309</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910961</td>\n",
       "      <td>1862.93748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11JUN15</td>\n",
       "      <td>2011.4524</td>\n",
       "      <td>55727</td>\n",
       "      <td>1640</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.757917</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.024802</td>\n",
       "      <td>-0.068325</td>\n",
       "      <td>-0.079274</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.93348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG10</td>\n",
       "      <td>2011.6057</td>\n",
       "      <td>55783</td>\n",
       "      <td>1648</td>\n",
       "      <td>3</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.761025</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.178436</td>\n",
       "      <td>-0.087887</td>\n",
       "      <td>-0.207460</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.93815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG11</td>\n",
       "      <td>2011.6085</td>\n",
       "      <td>55784</td>\n",
       "      <td>1648</td>\n",
       "      <td>4</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.757568</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.080286</td>\n",
       "      <td>-0.065957</td>\n",
       "      <td>-0.107477</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.92224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG12</td>\n",
       "      <td>2011.6112</td>\n",
       "      <td>55785</td>\n",
       "      <td>1648</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.761642</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.032072</td>\n",
       "      <td>-0.074917</td>\n",
       "      <td>-0.182729</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.92939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>AZCN</td>\n",
       "      <td>11AUG19</td>\n",
       "      <td>2011.6304</td>\n",
       "      <td>55792</td>\n",
       "      <td>1649</td>\n",
       "      <td>5</td>\n",
       "      <td>-107.9</td>\n",
       "      <td>-977</td>\n",
       "      <td>-0.757756</td>\n",
       "      <td>4078731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.071012</td>\n",
       "      <td>-0.142379</td>\n",
       "      <td>-0.285496</td>\n",
       "      <td>36.839793</td>\n",
       "      <td>-107.910963</td>\n",
       "      <td>1862.91815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4110 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      site  YYMMMDD  yyyy.yyyy  __MJD  week  d  reflon  _e0(m)  __east(m)  \\\n",
       "0     AZCN  99MAY10  1999.3539  51308  1009  1  -107.9    -977  -0.744686   \n",
       "1     AZCN  99MAY11  1999.3566  51309  1009  2  -107.9    -977  -0.741628   \n",
       "2     AZCN  99MAY12  1999.3593  51310  1009  3  -107.9    -977  -0.742445   \n",
       "3     AZCN  99MAY13  1999.3621  51311  1009  4  -107.9    -977  -0.744588   \n",
       "4     AZCN  99MAY14  1999.3648  51312  1009  5  -107.9    -977  -0.746577   \n",
       "...    ...      ...        ...    ...   ... ..     ...     ...        ...   \n",
       "4105  AZCN  11JUN15  2011.4524  55727  1640  3  -107.9    -977  -0.757917   \n",
       "4106  AZCN  11AUG10  2011.6057  55783  1648  3  -107.9    -977  -0.761025   \n",
       "4107  AZCN  11AUG11  2011.6085  55784  1648  4  -107.9    -977  -0.757568   \n",
       "4108  AZCN  11AUG12  2011.6112  55785  1648  5  -107.9    -977  -0.761642   \n",
       "4109  AZCN  11AUG19  2011.6304  55792  1649  5  -107.9    -977  -0.757756   \n",
       "\n",
       "      ____n0(m)  ...  _ant(m)  sig_e(m)  sig_n(m)  sig_u(m)  __corr_en  \\\n",
       "0       4078731  ...      0.0  0.000894  0.001071  0.003738   0.001207   \n",
       "1       4078731  ...      0.0  0.000838  0.001050  0.003623   0.021724   \n",
       "2       4078731  ...      0.0  0.000868  0.001055  0.003642  -0.001512   \n",
       "3       4078731  ...      0.0  0.001016  0.001200  0.004131   0.036789   \n",
       "4       4078731  ...      0.0  0.001342  0.001580  0.005565  -0.067832   \n",
       "...         ...  ...      ...       ...       ...       ...        ...   \n",
       "4105    4078731  ...      0.0  0.000828  0.001068  0.003440   0.024802   \n",
       "4106    4078731  ...      0.0  0.001333  0.001489  0.005270   0.178436   \n",
       "4107    4078731  ...      0.0  0.002455  0.002242  0.006725   0.080286   \n",
       "4108    4078731  ...      0.0  0.008280  0.003808  0.008938   0.032072   \n",
       "4109    4078731  ...      0.0  0.006698  0.003288  0.007855   0.071012   \n",
       "\n",
       "      __corr_eu  __corr_nu  _latitude(deg)  _longitude(deg)  __height(m)  \n",
       "0      0.067395  -0.150295       36.839793      -107.910961   1862.93747  \n",
       "1     -0.031813  -0.130306       36.839793      -107.910961   1862.93534  \n",
       "2     -0.034516  -0.086356       36.839793      -107.910961   1862.93970  \n",
       "3      0.025548  -0.159457       36.839793      -107.910961   1862.93930  \n",
       "4     -0.069363  -0.131309       36.839793      -107.910961   1862.93748  \n",
       "...         ...        ...             ...              ...          ...  \n",
       "4105  -0.068325  -0.079274       36.839793      -107.910963   1862.93348  \n",
       "4106  -0.087887  -0.207460       36.839793      -107.910963   1862.93815  \n",
       "4107  -0.065957  -0.107477       36.839793      -107.910963   1862.92224  \n",
       "4108  -0.074917  -0.182729       36.839793      -107.910963   1862.92939  \n",
       "4109  -0.142379  -0.285496       36.839793      -107.910963   1862.91815  \n",
       "\n",
       "[4110 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path ='../timeseries/AZCN.NA.tenv3'\n",
    "tenv3_sample = pd.read_csv(file_path, delim_whitespace=True )\n",
    "tenv3_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fefebe-70f9-443d-abc5-7766de048ee0",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### 2. Write a module to interact with the GNSS timeseries\n",
    "\n",
    "The module should have (at a minimum) the following four functions with their definitions:\n",
    "\n",
    "fit_timeseries(tlist,ylist) - accepts two lists: t (decimal year) and y (displacement timeseries)  as 1-D numpy arrays, and returns the least-squares velocity and uncertainty for that timeseries. If possible, try to re-use the line-fitting code you wrote for Lab 3 for this purpose.\n",
    "\n",
    "fit_velocities(filename) - accepts a filename, reads in the data, and uses fit_timeseries() to estimate the E, N and U components of velocity for that site.\n",
    "\n",
    "get_coordinates(filename) - accepts a filename and returns the average latitude, longitude, and elevation for that site over the time period.\n",
    "\n",
    "fit_all_velocities(folder,pattern) - accepts a folder name and a 'glob' pattern and returns a pandas data frame with the site name, coordinates, velocities and uncertainties.\n",
    "\n",
    "Finally, import your module and demonstrate each function below to show how it works and what it returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfcf58",
   "metadata": {},
   "source": [
    "### Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "754cba95-9568-4e92-a14f-44163332110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocity_analysis.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def import_tenv3(filename):\n",
    "    data = pd.read_csv(filename, delimiter='\\s+')\n",
    "    return data\n",
    "\n",
    "def fit_timeseries(tlist, ylist):\n",
    "    coeffs = np.polyfit(tlist, ylist, 1)\n",
    "    residuals = ylist - np.polyval(coeffs, tlist)\n",
    "    sigma = np.sqrt(np.sum(residuals**2) / (len(tlist) - 2))\n",
    "    sigma_coeffs = sigma / np.sqrt(np.sum((tlist - np.mean(tlist))**2))\n",
    "    return coeffs[0], sigma_coeffs\n",
    "\n",
    "def fit_velocities(filename, direction):\n",
    "    data = import_tenv3(filename)\n",
    "    tlist = data['yyyy.yyyy'].values\n",
    "    ylist = data[direction].values\n",
    "    velocity, uncertainty = fit_timeseries(tlist, ylist)\n",
    "    return velocity, uncertainty\n",
    "\n",
    "def get_coordinates(filename):\n",
    "    data = import_tenv3(filename)\n",
    "    latitude = np.mean(data['_latitude(deg)'].values)\n",
    "    longitude = np.mean(data['_longitude(deg)'].values)\n",
    "    elevation = np.mean(data['__height(m)'].values)\n",
    "    return latitude, longitude, elevation\n",
    "\n",
    "def fit_all_velocities(folder, pattern):\n",
    "    filenames = glob.glob(f\"{folder}/{pattern}\")\n",
    "    sites = []\n",
    "    coordinates = []\n",
    "    elevation = []\n",
    "    velocities_up = []\n",
    "    uncertainties_up = []\n",
    "    velocities_north = []\n",
    "    uncertainties_north = []\n",
    "    velocities_east = []\n",
    "    uncertainties_east = []\n",
    "    for filename in filenames:\n",
    "        site = filename.split('/')[-1].split('.')[0]\n",
    "        lat, lon, elev = get_coordinates(filename)\n",
    "        coordinates.append([lat, lon])\n",
    "        elevation.append(elev)\n",
    "        \n",
    "        vel_up, unc_up = fit_velocities(filename, '____up(m)')\n",
    "        velocities_up.append(vel_up)\n",
    "        uncertainties_up.append(unc_up)\n",
    "\n",
    "        vel_north, unc_north = fit_velocities(filename, '_north(m)')\n",
    "        velocities_north.append(vel_north)\n",
    "        uncertainties_north.append(unc_north)\n",
    "\n",
    "        vel_east, unc_east = fit_velocities(filename, '__east(m)')\n",
    "        velocities_east.append(vel_east)\n",
    "        uncertainties_east.append(unc_east)\n",
    "\n",
    "        sites.append(site)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Site': sites,\n",
    "        'Coordinates': coordinates,\n",
    "        'Elevation': elevation,\n",
    "        'Velocity_Up': velocities_up,\n",
    "        'Uncertainty_Up': uncertainties_up,\n",
    "        'Velocity_North': velocities_north,\n",
    "        'Uncertainty_North': uncertainties_north,\n",
    "        'Velocity_East': velocities_east,\n",
    "        'Uncertainty_East': uncertainties_east\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed817433",
   "metadata": {},
   "source": [
    "### Demonstration: Fit_timeseries function\n",
    "Calculates the least_squares velocity and uncertainty for a decimal year ('yyyy.yyyy') and displacement value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6735c1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imput of tlist: e.g., 1999.3539 and displacement (up [m]): e.g., 0.937473 returns uncertainty: -0.0008614640076356199 and velocity: 2.843238017220529e-05\n"
     ]
    }
   ],
   "source": [
    "import velocity_analysis\n",
    "\n",
    "# Example for AZCN file:\n",
    "folder = \"/Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5/timeseries\"\n",
    "pattern = \"AZCN.NA.tenv3\"\n",
    "\n",
    "filenames = glob.glob(f\"{folder}/{pattern}\")\n",
    "\n",
    "for filename in filenames:\n",
    "    data = pd.read_csv(filename, delimiter='\\s+')\n",
    "    data = import_tenv3(filename)\n",
    "    tlist = data['yyyy.yyyy'].values\n",
    "    ylist = data['____up(m)'].values\n",
    "\n",
    "    fit_timeseries = velocity_analysis.fit_timeseries(tlist, ylist)\n",
    "\n",
    "    print(f'Imput of tlist: e.g., {tlist[0]} and displacement (up [m]): e.g., {ylist[0]} returns uncertainty: {fit_timeseries[0]} and velocity: {fit_timeseries[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f5b82",
   "metadata": {},
   "source": [
    "### Demonstration: fit_velocities function\n",
    "\n",
    "Uses the 'fit_timeseries function to pull velocity and uncertainty calculations for each direction (Up, North, East)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e78b1c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uses fit_timeseries function for each file, e.g., AZCN.NA.tenv3, and for each direction, e.g., ____up(m), to pull velocity: -0.0008614640076356199 and uncertainty: 2.843238017220529e-05\n"
     ]
    }
   ],
   "source": [
    "import velocity_analysis\n",
    "\n",
    "# Example for AZCN file:\n",
    "folder = \"/Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5/timeseries\"\n",
    "pattern = \"AZCN.NA.tenv3\"\n",
    "\n",
    "filenames = glob.glob(f\"{folder}/{pattern}\")\n",
    "\n",
    "for filename in filenames:\n",
    "    data = pd.read_csv(filename, delimiter='\\s+')\n",
    "    direction = '____up(m)'\n",
    "    fit_velocities = velocity_analysis.fit_velocities(filename, direction)\n",
    "\n",
    "print(f'Uses fit_timeseries function for each file, e.g., {pattern}, and for each direction, e.g., {direction}, to pull velocity: {fit_velocities[0]} and uncertainty: {fit_velocities[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd0469",
   "metadata": {},
   "source": [
    "### Demonstration: get_coordinates function\n",
    "Pulls the latitude, longitude, and elevation data for each site (file), and calculates the mean latitude, longitude, and elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4c5e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From file AZCN.NA.tenv3, pull latitude: 36.839792950604185, longitude: -107.910962404209, and height (elevation) [m]: 1862.9388360243308\n"
     ]
    }
   ],
   "source": [
    "import velocity_analysis\n",
    "\n",
    "# Example for AZCN file:\n",
    "folder = \"/Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5/timeseries\"\n",
    "pattern = \"AZCN.NA.tenv3\"\n",
    "\n",
    "filenames = glob.glob(f\"{folder}/{pattern}\")\n",
    "\n",
    "for filename in filenames:\n",
    "    data = pd.read_csv(filename, delimiter='\\s+')\n",
    "    coordinates = velocity_analysis.get_coordinates(filename)\n",
    "\n",
    "print(f'From file {pattern}, pull latitude: {coordinates[0]}, longitude: {coordinates[1]}, and height (elevation) [m]: {coordinates[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9750193c",
   "metadata": {},
   "source": [
    "### Demonstration: fit_all_velocities function\n",
    "Utilizes 'glob' to look through all the .tenv3 files to get the velocity and uncertainty calculations for each direction (North, East, Up), the mean coordinates (latidue, longitude), and mean elevation for each site (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fe7e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Site                                Coordinates    Elevation  Velocity_Up  \\\n",
      "0  RG01   [34.667072418745406, -108.0438129456121]  2157.544590    -0.001694   \n",
      "1  SC01    [34.0679525903593, -106.96654343614426]  2097.379776     0.000436   \n",
      "2  AZCN    [36.839792950604185, -107.910962404209]  1862.938836    -0.000861   \n",
      "3  P034     [34.94561936925882, -106.459267663182]  1810.912904    -0.000354   \n",
      "4  P028   [36.03168469970933, -107.90840970082284]  1933.112591    -0.000650   \n",
      "5  P029  [38.439190420106776, -107.63804444204796]  2455.374920     0.002059   \n",
      "6  NMLG   [35.03995261508493, -107.37233835135558]  1763.225418    -0.000454   \n",
      "7  CTI4   [37.15291819162043, -107.75609089748136]  2017.964552    -0.002306   \n",
      "8  MC10  [38.455598434474396, -107.87845670801819]  1808.589875    -0.001166   \n",
      "9  TC01   [37.93803350458362, -107.81333275154333]  2677.537224    -0.000501   \n",
      "\n",
      "   Uncertainty_Up  Velocity_North  Uncertainty_North  Velocity_East  \\\n",
      "0        0.000022        0.001949           0.000009      -0.001049   \n",
      "1        0.000010        0.001673           0.000005      -0.000562   \n",
      "2        0.000028        0.002620           0.000009      -0.001096   \n",
      "3        0.000011        0.001744           0.000004      -0.000230   \n",
      "4        0.000010        0.001874           0.000005      -0.000758   \n",
      "5        0.000014       -0.000806           0.000007      -0.003157   \n",
      "6        0.000022        0.001692           0.000007      -0.001053   \n",
      "7        0.000042        0.001607           0.000008      -0.001705   \n",
      "8        0.000032        0.002116           0.000008      -0.000090   \n",
      "9        0.000146        0.001459           0.000046      -0.000465   \n",
      "\n",
      "   Uncertainty_East  \n",
      "0          0.000007  \n",
      "1          0.000005  \n",
      "2          0.000013  \n",
      "3          0.000004  \n",
      "4          0.000004  \n",
      "5          0.000007  \n",
      "6          0.000008  \n",
      "7          0.000009  \n",
      "8          0.000010  \n",
      "9          0.000060  \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "import velocity_analysis\n",
    "\n",
    "folder = \"/Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5/timeseries\"\n",
    "pattern = \"*.tenv3\"\n",
    "result_df = velocity_analysis.fit_all_velocities(folder, pattern)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff7646-860f-4a87-accd-a77e1c41d0a4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 3. Upload the module to GitHub, along with a README.md file explaining briefly how to use it.\n",
    "\n",
    "Enter a link to your GitHub repository here for me to check out: \n",
    "\n",
    "GitHub: [AdrianMarzil](https://github.com/AdrianMarzil)\n",
    "<br>Lab 5 Link: [Lab5_Abstraction](https://github.com/AdrianMarzil/CompMethods_EPS522/tree/672690f5eae0104104de0fa46089611b3882a693/Labs/Lab%205)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8beca1f-c264-4bb0-8bdb-393a3f1194b3",
   "metadata": {},
   "source": [
    "### 4. Use the timeseries calculation module you created\n",
    "\n",
    "Using at most 5 lines of code, import the module you created above and use it to estimate the timeseries for all 10 of the sites, print them out, and save the results to a new file 'site_velocities.csv'. Feel free to download more sites as well and put them in the folder too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1394f71a-8eba-42d7-81a9-23c5b108a9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Site                                Coordinates    Elevation  Velocity_Up  \\\n",
      "0  RG01   [34.667072418745406, -108.0438129456121]  2157.544590    -0.001694   \n",
      "1  SC01    [34.0679525903593, -106.96654343614426]  2097.379776     0.000436   \n",
      "2  AZCN    [36.839792950604185, -107.910962404209]  1862.938836    -0.000861   \n",
      "3  P034     [34.94561936925882, -106.459267663182]  1810.912904    -0.000354   \n",
      "4  P028   [36.03168469970933, -107.90840970082284]  1933.112591    -0.000650   \n",
      "5  P029  [38.439190420106776, -107.63804444204796]  2455.374920     0.002059   \n",
      "6  NMLG   [35.03995261508493, -107.37233835135558]  1763.225418    -0.000454   \n",
      "7  CTI4   [37.15291819162043, -107.75609089748136]  2017.964552    -0.002306   \n",
      "8  MC10  [38.455598434474396, -107.87845670801819]  1808.589875    -0.001166   \n",
      "9  TC01   [37.93803350458362, -107.81333275154333]  2677.537224    -0.000501   \n",
      "\n",
      "   Uncertainty_Up  Velocity_North  Uncertainty_North  Velocity_East  \\\n",
      "0        0.000022        0.001949           0.000009      -0.001049   \n",
      "1        0.000010        0.001673           0.000005      -0.000562   \n",
      "2        0.000028        0.002620           0.000009      -0.001096   \n",
      "3        0.000011        0.001744           0.000004      -0.000230   \n",
      "4        0.000010        0.001874           0.000005      -0.000758   \n",
      "5        0.000014       -0.000806           0.000007      -0.003157   \n",
      "6        0.000022        0.001692           0.000007      -0.001053   \n",
      "7        0.000042        0.001607           0.000008      -0.001705   \n",
      "8        0.000032        0.002116           0.000008      -0.000090   \n",
      "9        0.000146        0.001459           0.000046      -0.000465   \n",
      "\n",
      "   Uncertainty_East  \n",
      "0          0.000007  \n",
      "1          0.000005  \n",
      "2          0.000013  \n",
      "3          0.000004  \n",
      "4          0.000004  \n",
      "5          0.000007  \n",
      "6          0.000008  \n",
      "7          0.000009  \n",
      "8          0.000010  \n",
      "9          0.000060  \n"
     ]
    }
   ],
   "source": [
    "import velocity_analysis\n",
    "\n",
    "# Specify the folder and pattern for your timeseries files\n",
    "folder_path = '/Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5/timeseries'\n",
    "file_pattern = '*.NA.tenv3'\n",
    "\n",
    "# Use the module to estimate velocities for all sites\n",
    "df = velocity_analysis.fit_all_velocities(folder_path, file_pattern)\n",
    "\n",
    "# Print the results\n",
    "print(df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "df.to_csv('site_velocities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-terminology",
   "metadata": {},
   "source": [
    "### 5. Re-use your module to estimate sea level rise rates\n",
    "\n",
    "Go to the following page and download at least 5 monthly sea level timeseries spanning at least 100 years: https://psmsl.org/products/gloss/glossmap.html. Place them in a new folder.\n",
    "\n",
    "(To download the data: click a station icon on the map, then click the station number/name (first link in the pop-up, e.g. \"155: Honolulu\". Then right-click the link next to the plot of monthly data (\"Download monthly mean sea level data.\") and save it as a file.)\n",
    "\n",
    "Now, create a new function \"fit_tide_gauge\" in your module that re-uses your function \"fit_timeseries\" to return the relative sea level rate of change for a given station. \n",
    "\n",
    "Next, modify your function \"fit_all_velocities\" to accept a \"type\" parameter (GNSS or tide), and re-use it to estimate the rates for all the tide gauges you downloaded. Print out the results below.\n",
    "\n",
    "Finally, update your github repository with this new version of the module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dee49e-817a-47b2-af0d-fb6e811650f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidal_analysis.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def import_rlrdata(filename):\n",
    "    data = pd.read_csv(filename, delimiter=';', header=None, usecols=[0, 1], names=['yyyy.yyyy', 'elevation'])\n",
    "    data.replace(-9999, np.nan, inplace=True)  # Replace -9999 with NaN\n",
    "    return data\n",
    "\n",
    "def fit_timeseries(tlist, ylist):\n",
    "    coeffs = np.polyfit(tlist, ylist, 1)\n",
    "    residuals = ylist - np.polyval(coeffs, tlist)\n",
    "    sigma = np.sqrt(np.sum(residuals**2) / (len(tlist) - 2))\n",
    "    sigma_coeffs = sigma / np.sqrt(np.sum((tlist - np.mean(tlist))**2))\n",
    "    return coeffs[0], sigma_coeffs\n",
    "\n",
    "def fit_tide_gauge(filename):\n",
    "    data = import_rlrdata(filename)\n",
    "    tlist = data['yyyy.yyyy'].values\n",
    "    ylist = data['elevation'].values + 3.096  # Adding 3.096 to all elevation values\n",
    "    rate, uncertainty = fit_timeseries(tlist, ylist)\n",
    "    return rate, uncertainty\n",
    "\n",
    "def fit_all_rates(folder, pattern):\n",
    "    filenames = glob.glob(f\"{folder}/{pattern}\")\n",
    "    stations = []\n",
    "    rates = []\n",
    "    uncertainties = []\n",
    "    for filename in filenames:\n",
    "        station = filename.split('/')[-1].split('.')[0]\n",
    "        rate, uncertainty = fit_tide_gauge(filename)\n",
    "        stations.append(station)\n",
    "        rates.append(rate)\n",
    "        uncertainties.append(uncertainty)\n",
    "    df = pd.DataFrame({\n",
    "        'Station': stations,\n",
    "        'Rate (m)': rates,\n",
    "        'Uncertainty': uncertainties\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "345c6200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station        Rate  Uncertainty\n",
      "0     167  584.196581    29.364620\n",
      "1     165  648.266070    32.474093\n",
      "2      10   -1.822044     1.538391\n",
      "3     256   79.665016    18.556294\n",
      "4    1355 -746.889132   265.745177\n"
     ]
    }
   ],
   "source": [
    "import tidal_analysis\n",
    "\n",
    "# Specify the folder and pattern for your timeseries files\n",
    "folder_path = '/Users/Adrian/Documents/VS CODE/CompMethods_EPS522/Labs/Lab 5/tidal_timeseries'\n",
    "file_pattern = '*.rlrdata'\n",
    "\n",
    "# Use the module to estimate velocities for all sites\n",
    "df = tidal_analysis.fit_all_rates(folder_path, file_pattern)\n",
    "\n",
    "# Print the results\n",
    "print(df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "df.to_csv('site_tides.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d45c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
